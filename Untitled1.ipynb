{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a3b088-b0c1-4fb4-8f41-91e73398a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing opencv-python...\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Installing numpy...\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Installing keras...\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.11/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Installing tensorflow...\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Installing h5py...\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from h5py) (1.26.4)\n",
      "All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def install_requirements(file_path=\"requirements.txt\"):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            libraries = file.readlines()\n",
    "\n",
    "        libraries = [lib.strip() for lib in libraries]\n",
    "\n",
    "        for library in libraries:\n",
    "            if library:\n",
    "                print(f\"Installing {library}...\")\n",
    "                subprocess.check_call([ \"pip\", \"install\", library ])\n",
    "                \n",
    "        print(\"All libraries installed successfully!\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "install_requirements(\"requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac1c83e-495d-4058-b55a-601dd44edd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording video for 10 seconds...\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step\n",
      "Predicted Emotion: happy\n",
      "Playing happy song: https://www.youtube.com/watch?v=LjhCEhWiKXk&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import webbrowser\n",
    "from keras.models import model_from_json\n",
    "from time import time\n",
    "\n",
    "# Paths to model files\n",
    "json_file_path = \"emotiondetector.json\"\n",
    "h5_file_path = \"emotiondetector.h5\"\n",
    "\n",
    "# Load the trained emotion detection model\n",
    "try:\n",
    "    with open(json_file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(h5_file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "haar_file = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "# Define emotion labels and corresponding songs\n",
    "labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "\n",
    "# Define song URLs for each emotion\n",
    "songs = {\n",
    "    'angry': [\n",
    "        'https://www.youtube.com/watch?v=Vrr3lRLjZ1Y&list=PLknqyEOvGo1YgL11BN1m-YOxaFHl29elY',\n",
    "        'https://www.youtube.com/watch?v=eHbNU9WuVgw&list=PLknqyEOvGo1YgL11BN1m-YOxaFHl29elY&index=2'\n",
    "    ],\n",
    "    'disgust': [\n",
    "        'https://www.youtube.com/watch?v=0yySNUU5P2g',\n",
    "        'https://www.youtube.com/watch?v=MKk1u5RMTn4'\n",
    "    ],\n",
    "    'fear': [\n",
    "        'https://www.youtube.com/watch?v=kNfZt5JWYWU',\n",
    "        'https://www.youtube.com/watch?v=CKpbdCciELk'\n",
    "    ],\n",
    "    'happy': [\n",
    "        'https://www.youtube.com/watch?v=LjhCEhWiKXk&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1',\n",
    "        'https://www.youtube.com/watch?v=iPUmE-tne5U&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1&index=3'\n",
    "    ],\n",
    "    'neutral': [\n",
    "        'https://www.youtube.com/watch?v=pJgoHgpsb9I&list=PLP2qAKm-AAm9hIxpLbaMOcG2428lrssd5',\n",
    "        'https://www.youtube.com/watch?v=KfDr_7LN-Ew&list=PLP2qAKm-AAm9hIxpLbaMOcG2428lrssd5&index=3'\n",
    "    ],\n",
    "    'sad': [\n",
    "        'https://www.youtube.com/watch?v=f4Y3b7un4LE&list=PLgzTt0k8mXzHcKebL8d0uYHfawiARhQja',\n",
    "        'https://www.youtube.com/watch?v=cW8VLC9nnTo&list=PLgzTt0k8mXzHcKebL8d0uYHfawiARhQja&index=4'\n",
    "    ],\n",
    "    'surprise': [\n",
    "        'https://www.youtube.com/watch?v=Ldn11dMHTJ8&list=PL-nuykztplfc-uD_5VhZ6vaK1p3muRF1i',\n",
    "        'https://www.youtube.com/watch?v=EdvydlHCViY&list=PL-nuykztplfc-uD_5VhZ6vaK1p3muRF1i&index=4'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to extract features from image\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "# Function to play a random song from the list\n",
    "def play_random_song(emotion):\n",
    "    if emotion in songs:\n",
    "        song_url = random.choice(songs[emotion])\n",
    "        webbrowser.open(song_url)\n",
    "        print(f\"Playing {emotion} song: {song_url}\")\n",
    "\n",
    "# Initialize webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Error: Camera could not be opened. Please check your camera and permissions.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Recording video for 10 seconds...\")\n",
    "start_time = time()\n",
    "frames = []\n",
    "\n",
    "# Record video for 10 seconds\n",
    "while True:\n",
    "    ret, frame = webcam.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from webcam.\")\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    cv2.imshow(\"Recording\", frame)\n",
    "    if time() - start_time >= 10:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Process the recorded frames\n",
    "gray_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames]\n",
    "faces_detected = []\n",
    "\n",
    "for gray_frame in gray_frames:\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray_frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (48, 48))\n",
    "        faces_detected.append(face)\n",
    "\n",
    "\n",
    "\n",
    "if faces_detected:\n",
    "    # Predict the emotion based on the detected faces\n",
    "    face_images = np.array([extract_features(face) for face in faces_detected])\n",
    "    face_images = np.vstack(face_images)\n",
    "    predictions = model.predict(face_images)\n",
    "    avg_prediction = np.mean(predictions, axis=0)\n",
    "    emotion_label = labels[avg_prediction.argmax()]\n",
    "    print(f\"Predicted Emotion: {emotion_label}\")\n",
    "\n",
    "    # Play a random song based on the detected emotion\n",
    "    play_random_song(emotion_label)\n",
    "else:\n",
    "    print(\"No faces detected in the recorded video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92a65e1-97f7-4bc2-ada4-ec3ddcf8db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording video for 10 seconds...\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n",
      "Predicted Emotion: happy\n",
      "Playing happy song: https://www.youtube.com/watch?v=iPUmE-tne5U&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1&index=3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import webbrowser\n",
    "from keras.models import model_from_json\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "# Check if running on Linux and set display variable for X11 forwarding (if needed)\n",
    "if os.name == 'posix' and \"DISPLAY\" not in os.environ:\n",
    "    os.environ[\"DISPLAY\"] = \":0\"\n",
    "\n",
    "# Paths to model files\n",
    "json_file_path = \"emotiondetector.json\"\n",
    "h5_file_path = \"emotiondetector.h5\"\n",
    "\n",
    "# Load the trained emotion detection model\n",
    "try:\n",
    "    with open(json_file_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(h5_file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "haar_file = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "# Define emotion labels and corresponding songs\n",
    "labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "\n",
    "# Define song URLs for each emotion\n",
    "songs = {\n",
    "    'angry': [\n",
    "        'https://www.youtube.com/watch?v=Vrr3lRLjZ1Y&list=PLknqyEOvGo1YgL11BN1m-YOxaFHl29elY',\n",
    "        'https://www.youtube.com/watch?v=eHbNU9WuVgw&list=PLknqyEOvGo1YgL11BN1m-YOxaFHl29elY&index=2'\n",
    "    ],\n",
    "    'disgust': [\n",
    "        'https://www.youtube.com/watch?v=0yySNUU5P2g',\n",
    "        'https://www.youtube.com/watch?v=MKk1u5RMTn4'\n",
    "    ],\n",
    "    'fear': [\n",
    "        'https://www.youtube.com/watch?v=kNfZt5JWYWU',\n",
    "        'https://www.youtube.com/watch?v=CKpbdCciELk'\n",
    "    ],\n",
    "    'happy': [\n",
    "        'https://www.youtube.com/watch?v=LjhCEhWiKXk&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1',\n",
    "        'https://www.youtube.com/watch?v=iPUmE-tne5U&list=PL1VuYyZcPYIJTP3W_x0jq9olXviPQlOe1&index=3'\n",
    "    ],\n",
    "    'neutral': [\n",
    "        'https://www.youtube.com/watch?v=pJgoHgpsb9I&list=PLP2qAKm-AAm9hIxpLbaMOcG2428lrssd5',\n",
    "        'https://www.youtube.com/watch?v=KfDr_7LN-Ew&list=PLP2qAKm-AAm9hIxpLbaMOcG2428lrssd5&index=3'\n",
    "    ],\n",
    "    'sad': [\n",
    "        'https://www.youtube.com/watch?v=f4Y3b7un4LE&list=PLgzTt0k8mXzHcKebL8d0uYHfawiARhQja',\n",
    "        'https://www.youtube.com/watch?v=cW8VLC9nnTo&list=PLgzTt0k8mXzHcKebL8d0uYHfawiARhQja&index=4'\n",
    "    ],\n",
    "    'surprise': [\n",
    "        'https://www.youtube.com/watch?v=Ldn11dMHTJ8&list=PL-nuykztplfc-uD_5VhZ6vaK1p3muRF1i',\n",
    "        'https://www.youtube.com/watch?v=EdvydlHCViY&list=PL-nuykztplfc-uD_5VhZ6vaK1p3muRF1i&index=4'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "def play_random_song(emotion):\n",
    "    if emotion in songs:\n",
    "        song_url = random.choice(songs[emotion])\n",
    "        webbrowser.open(song_url)\n",
    "        print(f\"Playing {emotion} song: {song_url}\")\n",
    "\n",
    "# Initialize webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Error: Camera could not be opened. Please check your camera and permissions.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Recording video for 10 seconds...\")\n",
    "start_time = time()\n",
    "frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = webcam.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from webcam.\")\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or time() - start_time >= 10:\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "gray_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames]\n",
    "faces_detected = []\n",
    "\n",
    "for gray_frame in gray_frames:\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray_frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (48, 48))\n",
    "        faces_detected.append(face)\n",
    "\n",
    "if faces_detected:\n",
    "    face_images = np.array([extract_features(face) for face in faces_detected])\n",
    "    face_images = np.vstack(face_images)\n",
    "    predictions = model.predict(face_images)\n",
    "    avg_prediction = np.mean(predictions, axis=0)\n",
    "    emotion_label = labels[avg_prediction.argmax()]\n",
    "    print(f\"Predicted Emotion: {emotion_label}\")\n",
    "    play_random_song(emotion_label)\n",
    "else:\n",
    "    print(\"No faces detected in the recorded video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372efaa-9400-4bfd-b3f7-bdc6d289ec26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
